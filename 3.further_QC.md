Review coverage to see if purge_haplotigs isnt working right for some reason

```
samtools faidx purged.fa  # This generates a file called purged.fa.fai
```
creates index file for purged assembly

```
cut -f 1-2 purged.fa.fai > genome.txt
```
cut the first 2 cols of fa.fai to take the scaffold length and name > tab sep txt file

```
bedtools makewindows -g genome.txt -w 20000 > purged_genome_windows.bed
```
use makewindows to make windows frm txt file w lengths and scaffold names
This file will contain the windows of the genome. Each line will represent a window, specifying the chromosome (scaffold name), start position, and end position.

```
bedtools coverage -a purged_genome_windows.bed -b align_rerun.bam -mean > coverage_20k_windows.txt
```
output file containing the mean coverage per window. Each line gives the window's scaffold name, start and end positions, and the average coverage for that window

-b align_rerun is the bam file of aligned rreads back to the genome i think (might be using the wrong ver. filing is a mess i need to be shot)

this needs a job - killed in terminal but im getting OOM errors

trying with samtools coverage/depth:
```
samtools coverage -m -o samtools_cov.txt align_rerun.bam
```
```
samtools depth -o samtools_depth.txt align_rerun.bam
```
find the average coverage?
```
samtools depth  align_rerun.bam  |  awk '{sum+=$3} END { print "Average = ",sum/603880988}'
```
sum/(genome size)
```
Average =  150.487
```
**BLOBTOOLS**

BLAST - run blast search on genome
```
blastn \
-task megablast \
-query purged.fa \
-db nt \
-outfmt '6 qseqid staxids bitscore std' \
-max_target_seqs 1 \
-max_hsps 1 \
-num_threads 8 \
-evalue 1e-25 \
-out purgedassembly_vs_nt_megablast.out
```
OUTPUT: warning: examining 5 or more matches is recommended

this didn't finish running - run as job - how much mem? 32G/CPUS too low - up to 64? more mem or more cores.  or both. idk.

```
#!/bin/bash -e
#SBATCH --job-name=genomeblast # Job name (shows up in the queue)
#SBATCH --time=48:00:00      # Walltime (HH:MM:SS)
#SBATCH --mem=64G            # Memory in MB
#SBATCH --account=uoo02831
#SBATCH --cpus-per-task=64

module purge
module load BLAST
module load BLASTDB

blastn \
-task megablast \
-query purged.fa \
-db nt \
-outfmt '6 qseqid staxids bitscore std' \
-max_target_seqs 1 \
-max_hsps 1 \
-num_threads 64 \
-evalue 1e-25 \
-out purgedassembly_vs_nt_mts1.hsp1.1e25_megablast.out

echo "BLAST search complete"
```
timed out when ran for 24h, OOM when ran for 48 so up mem to 64/64.  IDK.   I feel crazy

blobltools
```
module load Miniconda3

##create conda environment
conda create -n blobtools
conda activate blobtools
conda install -c anaconda -c bioconda matplotlib docopt tqdm wget pyyaml git pysam

##when redoing do conda init before to let u go back in?
```
get nodesDB? - creating a local database that BlobTools can use to assign taxonomic information?
```
wget ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdump.tar.gz -P data/
tar zxf data/taxdump.tar.gz -C data/ nodes.dmp names.dmp
./blobtools nodesdb --nodes data/nodes.dmp --names data/names.dmp
```
create to create blobDB?
```
./blobtools create -i ../purged.fa -b ../align_rerun.bam -t **example/blast.out** -o example/test && \
./blobtools view -i example/test.blobDB.json && \
./blobtools plot -i example/test.blobDB.json
```
need a hits file for -t and change the other bits from example/test when get



meryl - rerunning kmer analysis

```
#!/bin/bash -e
#SBATCH --account=uoo02831
#SBATCH --job-name=meryl
#SBATCH --time=02:00:00
#SBATCH --cpus-per-task=16
#SBATCH --mem=64G
#SBATCH --partition=milan

# Modules
module purge
module load Merqury/1.3-Miniconda3

# Run
meryl count k=30 memory=64 threads=16 \
  gbrev_hifi_reads.fq.gz \
  output gb-read-kmerdb.meryl
```
creates kmer db 

```
meryl histogram gb-read-kmerdb.meryl > gb-read-kmerdb.hist
```
creates kmer hist from db
place in genomescope2.0:

http://genomescope.org/genomescope2.0/analysis.php?code=ech9pLIBECiwO7EhVusf

have a look and see if it looks the same as the jellyfish one
the model fit still not rly great but idk whattttttt thagt means for anything if im being honest

FASTPLONG

```
conda create -n fastplong
conda activate fastplong

conda install conda-forge::libdeflate
conda install conda-forge::isa-l
conda install conda-forge::libhwy

git clone https://github.com/OpenGene/fastplong.git
##conda install -c bioconda fastplong
```
idk if i need that last bit

