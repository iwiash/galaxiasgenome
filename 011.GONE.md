Clone repository
```
git clone https://github.com/esrud/GONE.git
```

Use subset VCFs of noislands_renamed_full_sorted.vcf that separate each pops

Make chrom map file
```
bcftools view -H ../subset_vcfs/12mile_only_renamed.vcf | cut -f 1 | uniq | awk '{print $0"\t"$0}' > 12mile.chrom-map.txt
```
Make .map/.ped files
```
vcftools --vcf ../subset_vcfs/12mile_only_renamed.vcf --chrom-map 12mile.chrom-map.txt --out 12mile --plink
```

Ok this is when it gets a bit stupid - gotta be a better way
```
Manually rm SCAFFOLD_000 in front of names with ctrl f replace in .map file
 - could definitely replace this with a sed cmd but for debugging of the actual gone script i want to move forward

cp .map and .ped files into gone directory - in future might have to do a hideous ln -s file struct for each lake
```

```
#!/bin/bash -e
#SBATCH --job-name=gone_testrun
#SBATCH --time=15:00:00
#SBATCH --mem=32G
#SBATCH --account=uoo02831
#SBATCH --cpus-per-task=12

bash script_GONE.sh subset_vcfs/12mile_only_renamed

echo "gone run complete'
```
## Stairway
```
module load Miniconda3

conda create -n easySFS
conda activate easySFS
conda install -c conda-forge numpy pandas scipy -y
git clone https://github.com/isaacovercast/easySFS.git
```
then copy appropriate files in and:
```
./easySFS.py -i all_samples.recode.vcf -p metadata_pops_samplenames_only_full.txt --preview
## use numbers from this (just choose # of samples i actually have) for next step

##test run with one of the pops
./easySFS.py -i all_samples.recode.vcf -p meta/chalice.txt --proj 13 -o chalice_sfs

output sfs:
14 folded "Lake-Chalice"
176.5889168180275 38.33151712546892 13.46539238703596 7.073674189736902 5.161099493191625 3.878491962002185 3.500908024537036 0 0 0 0 0 0 0
1 0 0 0 0 0 0 1 1 1 1 1 1 1
```
i think i need to replace the first value with one from stacks?? or from my vcf??
```
vcftools --vcf all_samples.recode.vcf --freq --out all_samples_freq_summary
## get monomorphic sites from allsamp summary stats?? thats my best bet but nesi not working :(
```
this didnt work - going to split the vcf file quickly using some loops i think..

```
for meta in *.txt; do
    cut -f1 "$meta" > "${meta%.txt}_sample_id.txt"
done

for pop_file in *_sample_id.txt; do
    pop_name="${pop_file%.txt}"
    vcftools --vcf ../all_samples.recode.vcf --keep $pop_file --recode --out "${pop_name}_filtered"
done

gzip *filtered.recode.vcf

```


## TOGA
Requires 2bit format

Convert gb ref to 2bit:

```
module load Miniconda3

conda activate

conda create -n fatotwobit
conda activate fatotwobit
conda install bioconda::ucsc-fatotwobit

faToTwoBit gb_hic_purged_softmasked.fa.masked gb_softmasked.2bit
```

Convert gff3 to bed?
```
module load BEDOPS

gff2bed < mikado.final.longest.gff3 > gb_anno.bed

```

Download Atlantic Salmon ref genome and convert to 2bit 
```
conda install -c conda-forge ncbi-datasets-cli

datasets download genome accession GCF_905237065.1 --include gff3,genome,seq-report
unzip -d atlantic_salmon ncbi_dataset.zip
## lowkey dont need all of those but may as well have them if needed

faToTwoBit atlantic_salmon/ncbi_dataset/data/GCF_905237065.1/GCF_905237065.1_Ssal_v3.1_genomic.fna salmo_salar.2bit
```

Other genomes:
```
## Northern pike
datasets download genome accession GCF_011004845.1 --include gff3,genome,seq-report
unzip -d northern_pike/ ncbi_dataset.zip

## Greater argentine
datasets download genome accession GCA_951799395.1 --include gff3,seq-report
unzip -d greater_argentine/ ncbi_dataset.zip

## Salamanderfish
datasets download genome accession GCA_049190665.1 --include gff3,genome,seq-report
unzip -d salamanderfish/ ncbi_dataset.zip

## Zebrafish
datasets download genome accession GCF_049306965.1 --include gff3,genome,seq-report
unzip -d zebrafish/ ncbi_dataset.zip
```
```
faToTwoBit greater_argentine/ncbi_dataset/data/GCA_951799395.1/GCA_951799395.1_fArgSil1.1_genomic.fna argentina_silus.2bit

faToTwoBit northern_pike/ncbi_dataset/data/GCF_011004845.1/GCF_011004845.1_fEsoLuc1.pri_genomic.fna esox_lucius.2bit

faToTwoBit salamanderfish/ncbi_dataset/data/GCA_049190665.1/GCA_049190665.1_fLepSal2.hap1_genomic.fna lepidogalaxias_salamandroides.2bit

faToTwoBit zebrafish/ncbi_dataset/data/GCF_049306965.1/GCF_049306965.1_GRCz12tu_genomic.fna danio_rerio.2bit
```

makelastchainz
```
git clone https://github.com/hillerlab/make_lastz_chains.git
cd make_lastz_chains

./install_dependencies.py
module load LASTZ
module load Nextflow

### Minimal example
./make_chains.py galaxias atl_salmon ../toga_genomes/gb_softmasked.2bit ../toga_genomes/salmo_salar.2bit --executor slurm --project_dir test_salmo -f

```
trying to do a test run in terminal but getting an error smh


Run toga (no chain file yet)
```
toga.py --project_dir togaout/ --limit_to_ref_chrom ptg000017l_1 
```

TRYING IN AORAKI
```
conda create -n TOGA_env python=3.11
conda activate TOGA_env
Conda install -c bioconda bedparse ucsc-fatotwobit ucsc-twobitinfo

git clone https://github.com/hillerlab/make_lastz_chains.git
cd make_lastz_chains/

conda install bioconda::lastz
module load nextflow  ## DONT WANNA FUCK ARND WITH THIS SO JUST LOAD MODULE FIRST

chmod +x install_dependencies.py 
./install_dependencies.py

```

problem with fatotwobit - libssl.so.1.0.0 error no such file fml
