Clone repository
```
git clone https://github.com/esrud/GONE.git
```

Use subset VCFs of noislands_renamed_full_sorted.vcf that separate each pops

Make chrom map file
```
bcftools view -H ../subset_vcfs/12mile_only_renamed.vcf | cut -f 1 | uniq | awk '{print $0"\t"$0}' > 12mile.chrom-map.txt
```
Make .map/.ped files
```
vcftools --vcf ../subset_vcfs/12mile_only_renamed.vcf --chrom-map 12mile.chrom-map.txt --out 12mile --plink
```

Ok this is when it gets a bit stupid - gotta be a better way
```
Manually rm SCAFFOLD_000 in front of names with ctrl f replace in .map file
 - could definitely replace this with a sed cmd but for debugging of the actual gone script i want to move forward

cp .map and .ped files into gone directory - in future might have to do a hideous ln -s file struct for each lake
```

```
#!/bin/bash -e
#SBATCH --job-name=gone_testrun
#SBATCH --time=15:00:00
#SBATCH --mem=32G
#SBATCH --account=uoo02831
#SBATCH --cpus-per-task=12

bash script_GONE.sh subset_vcfs/12mile_only_renamed

echo "gone run complete'
```
## Stairway
```
module load Miniconda3

conda create -n easySFS
conda activate easySFS
conda install -c conda-forge numpy pandas scipy -y
git clone https://github.com/isaacovercast/easySFS.git
```
then copy appropriate files in and:
```
./easySFS.py -i all_samples.recode.vcf -p metadata_pops_samplenames_only_full.txt --preview
## use numbers from this (just choose # of samples i actually have) for next step

##test run with one of the pops
./easySFS.py -i all_samples.recode.vcf -p meta/chalice.txt --proj 13 -o chalice_sfs

output sfs:
14 folded "Lake-Chalice"
176.5889168180275 38.33151712546892 13.46539238703596 7.073674189736902 5.161099493191625 3.878491962002185 3.500908024537036 0 0 0 0 0 0 0
1 0 0 0 0 0 0 1 1 1 1 1 1 1
```
i think i need to replace the first value with one from stacks?? or from my vcf??
```
vcftools --vcf all_samples.recode.vcf --freq --out all_samples_freq_summary
## get monomorphic sites from allsamp summary stats?? thats my best bet but nesi not working :(
```
this didnt work - going to split the vcf file quickly using some loops i think..

```
for meta in *.txt; do
    cut -f1 "$meta" > "${meta%.txt}_sample_id.txt"
done

for pop_file in *_sample_id.txt; do
    pop_name="${pop_file%.txt}"
    vcftools --vcf ../all_samples.recode.vcf --keep $pop_file --recode --out "${pop_name}_filtered"
done

gzip *filtered.recode.vcf

```




## TOGA
Requires 2bit format

Convert gb ref to 2bit:

```
module load Miniconda3

conda activate

conda create -n fatotwobit
conda activate fatotwobit
conda install bioconda::ucsc-fatotwobit

faToTwoBit gb_hic_purged_softmasked.fa.masked gb_softmasked.2bit
```

Download Atlantic Salmon ref genome and convert to 2bit 
```
conda install -c conda-forge ncbi-datasets-cli

datasets download genome accession GCF_905237065.1 --include gff3,rna,cds,protein,genome,seq-report
## lowkey dont need all of those but may as well have them if needed

faToTwoBit ncbi_dataset/data/GCF_905237065.1/GCF_905237065.1_Ssal_v3.1_genomic.fna salmo_salar.2bit
```
Convert gff3 to bed?
```
module load BEDOPS

gff2bed < mikado.final.longest.gff3 > gb_anno.bed

```
Run toga
```
toga.py --project_dir togaout/ --limit_to_ref_chrom ptg000017l_1 
