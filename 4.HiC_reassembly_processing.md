## Initial data processing

```
module load SAMtools
module load pigz
module load NanoComp
module load cutadapt
```

### 1. convert to fastq
```
samtools fastq -@4 GbrevPB.hifi_reads.bam | pigz > gbrev_hifi_reads.fq.gz
```
```
#Output:
[M::bam2fq_mainloop] discarded 0 singletons
[M::bam2fq_mainloop] processed 6826044 reads
```
### 2. NanoComp
```
NanoComp --fastq gbrev_hifi_reads.fq.gz --names Gbrev_PacBio_HiFi --outdir nanocomp_assembly_hifi
```
### 3. cutadapt
```
cutadapt -b "AAAAAAAAAAAAAAAAAATTAACGGAGGAGGAGGA;min_overlap=35" \
-b "ATCTCTCTCTTTTCCTCCTCCTCCGTTGTTGTTGTTGAGAGAGAT;min_overlap=45" \
--discard-trimmed \
-o /dev/null \
gbrev_hifi_reads.fq.gz \
-j 0 \
--revcomp \
-e 0.05
```
```
=== Summary ===

Total reads processed:               6,826,044
Reads with adapters:                         1 (0.0%)
Reverse-complemented:                        0 (0.0%)

== Read fate breakdown ==
Reads discarded as trimmed:                  1 (0.0%)
Reads written (passing filters):     6,826,043 (100.0%)

Total basepairs processed: 91,974,606,973 bp
Total written (filtered):  91,974,589,506 bp (100.0%)

=== Adapter 1 ===

Sequence: AAAAAAAAAAAAAAAAAATTAACGGAGGAGGAGGA; Type: variable 5'/3'; Length: 35; Trimmed: 0 times; Reverse-complemented: 0 times

=== Adapter 2 ===

Sequence: ATCTCTCTCTTTTCCTCCTCCTCCGTTGTTGTTGTTGAGAGAGAT; Type: variable 5'/3'; Length: 45; Trimmed: 1 times; Reverse-complemented: 0 times
0 times, it overlapped the 5' end of a read
1 times, it overlapped the 3' end or was within the read

Minimum overlap: 45
No. of allowed errors:
1-19 bp: 0; 20-39 bp: 1; 40-45 bp: 2

Overview of removed sequences (5')
length  count   expect  max.err error counts



Overview of removed sequences (3' or within)
length  count   expect  max.err error counts
17444   1       0.0     2       1
```

### 4. trim UMIS off HiC
```
zcat Bruce_fish_HiC_S1_R1_001.fastq.gz | awk '{ if(NR%2==0) {print substr($1,10)} else {print} }' | gzip > Fish_HiC_trimmed_R1_001.fastq.gz

zcat Bruce_fish_HiC_S1_R2_001.fastq.gz | awk '{ if(NR%2==0) {print substr($1,10)} else {print} }' | gzip > Fish_HiC_trimmed_R2_001.fastq.gz
```

## Hifiasm assembly
### 1. hifiasm assembly and conversion to fasta
```
#!/bin/bash -e
#SBATCH --job-name=SerialJob # job name (shows up in the queue)
#SBATCH --time=48:00:00      # Walltime (HH:MM:SS) 48h
#SBATCH --mem=230G          # Memory in MB
#SBATCH --account=uoo02831
#SBATCH --cpus-per-task=128
#SBATCH --partition=milan

module load hifiasm

hifiasm \
    -o GB_full_HIC \
    -t128 \
    --h1 Fish_HiC_trimmed_R1_001.fastq.gz \
    --h2 Fish_HiC_trimmed_R2_001.fastq.gz \
    gbrev_hifi_reads.fq.gz\
    2> test.log

echo "assembly done, starting conversion"

awk '/^S/{print ">"$2;print $3}' \
    GB_full_HIC.bp.p_ctg.gfa \
    > GB_full_HIC.p_ctg.fa

echo "conversion complete"

```

### 2. gfastats
```
module load gfastats

gfastats GB_full_HIC.p_ctg.fa
```
```
+++Assembly summary+++: 
# scaffolds: 664
Total scaffold length: 630588521
Average scaffold length: 949681.51
Scaffold N50: 7215088
Scaffold auN: 8253254.37
Scaffold L50: 27
Largest scaffold: 28003021
Smallest scaffold: 12723
# contigs: 664
Total contig length: 630588521
Average contig length: 949681.51
Contig N50: 7215088
Contig auN: 8253254.37
Contig L50: 27
Largest contig: 28003021
Smallest contig: 12723
# gaps in scaffolds: 0
Total gap length in scaffolds: 0
Average gap length in scaffolds: 0.00
Gap N50 in scaffolds: 0
Gap auN in scaffolds: 0.00
Gap L50 in scaffolds: 0
Largest gap in scaffolds: 0
Smallest gap in scaffolds: 0
Base composition (A:C:G:T): 176460736:138981680:138809043:176337062
GC content %: 44.05
# soft-masked bases: 0
# segments: 664
Total segment length: 630588521
Average segment length: 949681.51
# gaps: 0
# paths: 664
```
slightly smaller/slightly more contigs than non - HiC assembly

## Quality control
### 1. meryl
```
#!/bin/bash -e
#SBATCH --account=uoo02831
#SBATCH --job-name=meryl
#SBATCH --time=02:00:00
#SBATCH --cpus-per-task=16
#SBATCH --mem=64G
#SBATCH --partition=milan

# Modules
module purge
module load Merqury/1.3-Miniconda3

# Run
meryl count k=17 memory=64 threads=16 \
  gbrev_hifi_reads.fq.gz \
  output gb-hic-read-kmerdb.meryl
```
create hist - put in genomescope2
```
meryl histogram gb-hic-read-kmerdb.meryl > gb-hic-read-kmerdb.hist
```
http://genomescope.org/genomescope2.0/analysis.php?code=MBW0H4GmA4NoDrPLe755 #17mer (lowkey bad)

http://genomescope.org/genomescope2.0/analysis.php?code=hJkftalqzUQm2OGmWHIr #25mer (better)

http://genomescope.org/genomescope2.0/analysis.php?code=ech9pLIBECiwO7EhVusf #30mer (kind of best weirdly enough)

### 2. fastplong
gitclone fastplong into conda env - lowkey idk if putting it in a conda env is necessary.. idk anything about all that. but this is what i did so
```
conda create -n fastplong
conda activate fastplong

conda install conda-forge::libdeflate
conda install conda-forge::isa-l
conda install conda-forge::libhwy

git clone https://github.com/OpenGene/fastplong.git
```
run
```
fastplong -i gbrev_hifi_reads.fq.gz -o cleaned_gb_hifi_reads.fq
```
output says it didnt find any more adapters so take original reads file forward
also idk if fq is the right extension but since im not actually using it it doesnt matter anyway

### 3. Minimap2

Rerun minimap2 on HiC primary assembly

```
#!/bin/bash -e
#SBATCH --job-name=gbminimaphic # Job name (shows up in the queue)
#SBATCH --time=20:00:00      # Walltime (HH:MM:SS) 48h
#SBATCH --mem=32G            # Memory in MB
#SBATCH --account=uoo02831
#SBATCH --cpus-per-task=16

module load minimap2/2.24-GCC-11.3.0
module load SAMtools/1.16.1-GCC-11.3.0

minimap2 \
    -t 16 -ax map-hifi \
    GB_full_HIC.p_ctg.fa gbrev_hifi_reads.fq.gz \
    --secondary=no | samtools sort -m 5G -o hic_asm_minimap_align.bam -T temp.ali \
    2> minimap2_hic_errors.log

echo "alignment and file conversion complete"

```

this creates a sam out[it (-a flag) which i believe i needed for purge_haplotigs but need a paf file for purgedups oops
```
#!/bin/bash -e
#SBATCH --job-name=gbminimaphic # Job name (shows up in the queue)
#SBATCH --time=15:00:00      # Walltime (HH:MM:SS) 48h
#SBATCH --mem=32G            # Memory in MB
#SBATCH --account=uoo02831
#SBATCH --cpus-per-task=32

module load minimap2
module load pigz

minimap2 \
	-t 32 -x map-hifi \
	GB_full_HIC.p_ctg.fa gbrev_hifi_reads.fq.gz \
	> hic_minimap_align.paf \
	2> minimap_paf_errors.log

echo "alignment complete"

pigz -p 32 -c hic_minimap_align.paf > hic_minimap_align.paf.gz

echo "compression complete"

```


## 4. Purge_dups

```
module load purge_dups
module load minimap2
```

```
pbcstat hic_minimap_align.paf

calcuts PB.stat > cutoffs 2>calcults.log
```
produces PB.base.cov and PB.stat files

split assembly and do self-self alignment
```
split_fa GB_full.p_ctg.fa > GB_asm.split

minimap2 -xasm5 -DP gb_hic_asm.split gb_hic_asm.split | gzip -c - > gb_hic_asm.split.self.paf.gz
```

identify haplotigs and duplicates - places coordinates of dup/hap regions into file dup_sequences.bed
```
purge_dups -2 -T cutoffs -c PB.base.cov gb_hic_asm.split.self.paf.gz > dup_sequences.bed 2> purge_dups.log
```
purge duplicates from full genome using the bed file above
```
get_seqs -e -p gb_hic_purged dup_sequences.bed GB_full_HIC.p_ctg.fa
```
-e = rm only dups at the end of contigs - remove for more stringent but might cut out actual stuff
produces purged.fa and hap.fa (with prefix) - **gb_hic_purged.fa is final purged draft taken forwards**
```
[W::get_seqs_core] ptg000001l 3240733 3273834 is skipped
[W::get_seqs_core] ptg000007l 302571 1899292 is skipped
[W::get_seqs_core] ptg000009l 3740010 3829306 is skipped
[W::get_seqs_core] ptg000037l 656985 796933 is skipped
[W::get_seqs_core] ptg000038l 3478936 3545999 is skipped
[W::get_seqs_core] ptg000100l 1293521 1362279 is skipped
[W::get_seqs_core] ptg000192l 202589 420872 is skipped
```
### check gfastats of purged assembly:
```
#gb_hic_purged.fa
+++Assembly summary+++: 
# scaffolds: 278
Total scaffold length: 604930116
Average scaffold length: 2176007.61
Scaffold N50: 7780314
Scaffold auN: 8577137.58
Scaffold L50: 25
Largest scaffold: 28003021
Smallest scaffold: 17764
# contigs: 278
Total contig length: 604930116
Average contig length: 2176007.61
Contig N50: 7780314
Contig auN: 8577137.58
Contig L50: 25
Largest contig: 28003021
Smallest contig: 17764
# gaps in scaffolds: 0
Total gap length in scaffolds: 0
Average gap length in scaffolds: 0.00
Gap N50 in scaffolds: 0
Gap auN in scaffolds: 0.00
Gap L50 in scaffolds: 0
Largest gap in scaffolds: 0
Smallest gap in scaffolds: 0
Base composition (A:C:G:T): 170177384:132534868:132376761:169841103
GC content %: 43.79
# soft-masked bases: 0
# segments: 278
Total segment length: 604930116
Average segment length: 2176007.61
# gaps: 0
# paths: 278
```
way less contigs in the purged asm, also smaller - looks good

## Longstitch

```
longstitch run draft=gb_hic_purged reads=gbrev_hifi_reads t=8 out_prefix=gb_hic_fulldraft G=6e8 longmap=hifi
```
check this over but this is my guess of the parameters i need.  not sure if i should round the G= or not
This is taking ages - if doesnt run today run as  job tmrw

maybe also run the ark one? idk what that is but i do have a kmer database from meryl? idk
```
longstitch tigmint-ntLink-arks draft=gb_hic_purged reads=gbrev_hifi_reads kmer_db=(meryl kmer database) t=8 out_prefix=gb_hic_fulldraft_arks G=3.02465058e8 longmap=hifi
```

```
#!/bin/bash -e
#SBATCH --job-name=gblongstitch_nosym # Job name (shows up in the queue)
#SBATCH --time=10:00:00      # Walltime (HH:MM:SS) 48h
#SBATCH --mem=64G            # Memory in MB
#SBATCH --account=uoo02831
#SBATCH --cpus-per-task=8

module purge

module load LongStitch	

longstitch run \
	draft=gb_hic_purged reads=gbrev_hifi_reads \
	t=8 \
	out_prefix=gb_hic_fulldraft_600 \
	span=5 \ #or 10
	dist=1000 \ #or lower
	G=6e8 \
	longmap=hifi \
	2> longmap_err_nosym_600.log

echo "run complete"

```
** IMPORTANT: when running longstitch run on the actual data!!! not sym links as it runs into a memory corruption issue. **
Ran with 6GB of mem so can size down majorly

im unsure which file is the output for this but surely its the fulldraft one?

```
gfastats gb_hic_fulldraft_600.scaffolds.fa
```
```
+++Assembly summary+++: 
# scaffolds: 7421
Total scaffold length: 608380570
Average scaffold length: 81980.94
Scaffold N50: 8948147
Scaffold auN: 8877196.52
Scaffold L50: 23
Largest scaffold: 23509802
Smallest scaffold: 1
# contigs: 13648
Total contig length: 604821348
Average contig length: 44315.75
Contig N50: 548521
Contig auN: 1444694.68
Contig L50: 222
Largest contig: 8111915
Smallest contig: 1
# gaps in scaffolds: 6227
Total gap length in scaffolds: 3559222
Average gap length in scaffolds: 571.58
Gap N50 in scaffolds: 1603
Gap auN in scaffolds: 2410.05
Gap L50 in scaffolds: 643
Largest gap in scaffolds: 13308
Smallest gap in scaffolds: 20
Base composition (A:C:G:T): 169835862:132408726:132449641:170127119
GC content %: 43.79
# soft-masked bases: 94
# segments: 13648
Total segment length: 604821348
Average segment length: 44315.75
# gaps: 6227
# paths: 7421
```
this one is better than the last one was but is still way less contiguous than the input - also the contig N50 is way low but the scaffold N50 is higher.  Not sure what that means but idk doesnt seem ideal
## decided to call it at the purged genome before longstitch

## Repeatmodeler
create database
```
BuildDatabase -name gbrevDB gb_hic_purged.fa
```
```
Building database gbrevDB:
  Reading gb_hic_purged.fa...
Number of sequences (bp) added to database: 278 ( 604930116 bp )
```

run repeatmodeler
```
#!/bin/bash -e
#SBATCH --job-name=gblongstitch_nosym # Job name (shows up in the queue)
#SBATCH --time=72:00:00      # Walltime (HH:MM:SS) 48h
#SBATCH --mem=64G            # Memory in MB
#SBATCH --account=uoo02831
#SBATCH --cpus-per-task=32

module purge

module load RepeatModeler

RepeatModeler \
	-database gbrevDB \
	-pa 8 \
	-LTRStruct \
	>& repeatmodeler_run.out
```
-pa is how many jobs to run in parallel - default RMBlast runs using 4 cores each so 16/4 = 4 ...... i think

-LTRStruct runs the LTR structural discovery pipeline - idk if i need this but its in the example run so. whatever

timed out - up the time and the cores

keeps timing out add flag -recoverDir [ResultDir] option allows you to specify a diretory ( i.e RM_./ ) where a previous run of RepeatModeler was working and it will automatically determine how to continue the analysis.
